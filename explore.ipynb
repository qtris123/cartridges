{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8520a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "#train data\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "llama_0 = load_dataset(\"hazyresearch/m07d11_longhealth_synthesize_llama-3.2-3b_p10_n65536-0\")\n",
    "llama_1 = load_dataset(\"hazyresearch/m07d11_longhealth_synthesize_llama-3.2-3b_p10_n65536-1\")\n",
    "llama_2 = load_dataset(\"hazyresearch/m07d11_longhealth_synthesize_llama-3.2-3b_p10_n65536-2\") \n",
    "\n",
    "llama_0 = llama_0[\"train\"]\n",
    "llama_1 = llama_1[\"train\"]\n",
    "llama_2 = llama_2[\"train\"]\n",
    "\n",
    "llama_df = concatenate_datasets([llama_0, llama_1, llama_2])\n",
    "llama_df.to_parquet(\"/scratch/scholar/vo43/llama_longhealth.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a7ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longhealth train split is stored in: /scratch/scholar/vo43/train.parquet and /home/vo43/cartridges/train.parquet\n",
    "for split, dset in ds.items():\n",
    "    dset.to_parquet(f\"/scratch/scholar/vo43/{split}.parquet\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a51673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds_eval = load_dataset(\"hazyresearch/m07d11_longhealth_synthesize_qwen3-4b_p10_n65536-0\")\n",
    "for split, dset in ds_eval.items():\n",
    "    dset.to_parquet(f\"/scratch/scholar/vo43/{split}_eval.parquet\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a645a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a script to generate the text file\n",
    "from cartridges.data.longhealth.resources import LongHealthResource\n",
    "\n",
    "resource = LongHealthResource(LongHealthResource.Config(\n",
    "    patient_ids=[\"patient_01\", \"patient_02\", \"patient_03\", \"patient_04\", \"patient_05\", \"patient_06\", \"patient_07\", \"patient_08\", \"patient_09\", \"patient_10\",\n",
    "    \"patient_11\", \"patient_12\", \"patient_13\", \"patient_14\"]  # Choose your patients\n",
    "))\n",
    "context_text = resource.to_string()\n",
    "\n",
    "# Save to file\n",
    "with open(\"examples/arxiv/longhealth_context.txt\", \"w\") as f:\n",
    "    f.write(context_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792ac3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"hazyresearch/m07d28_mtob_synthesize_qwen3-4b_n65536-0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f50402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset, concatenate_datasets\n",
    "# import pandas as pd\n",
    "\n",
    "# # Login using e.g. `huggingface-cli login` to access this dataset\n",
    "# llama_0 = load_dataset(\"hazyresearch/m07d28_mtob_synthesize_llama-3.2-3b_n65536-0\")\n",
    "# llama_1 = load_dataset(\"hazyresearch/m07d28_mtob_synthesize_llama-3.2-3b_n65536-1\")\n",
    "\n",
    "# llama_0_df = next(iter(llama_0.values()))\n",
    "# llama_1_df = next(iter(llama_1.values()))\n",
    "\n",
    "# llama_0_df.to_parquet(f\"/scratch/scholar/vo43/llama_0_mtob.parquet\")\n",
    "\n",
    "# llamas_df = concatenate_datasets([llama_0_df, llama_1_df])\n",
    "# llamas_df.to_parquet(f\"/scratch/scholar/vo43/llama_mtob.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d8488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset, concatenate_datasets\n",
    "# import pandas as pd\n",
    "\n",
    "# qwen_0 = load_dataset(\"hazyresearch/m07d28_mtob_synthesize_qwen3-4b_n65536-0\")\n",
    "# qwen_1 = load_dataset(\"hazyresearch/m07d28_mtob_synthesize_qwen3-4b_n65536-1\")\n",
    "\n",
    "# qwen_0_df = next(iter(qwen_0.values()))\n",
    "# qwen_1_df = next(iter(qwen_1.values()))\n",
    "\n",
    "# qwen_0_df.to_parquet(f\"/scratch/scholar/vo43/qwen_0_mtob.parquet\")\n",
    "\n",
    "# qwens_df = concatenate_datasets([qwen_0_df, qwen_1_df]) \n",
    "# qwens_df.to_parquet(f\"/scratch/scholar/vo43/qwen_mtob.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cce4767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "with open(\"/scratch/scholar/vo43/llama_0_mtob.parquet\", \"rb\") as f:\n",
    "    llama_0 = pd.read_parquet(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c8e06b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llama_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf4b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.4kg\n"
     ]
    }
   ],
   "source": [
    "pred = \"\"\"{answer}\n",
    "12.4kg\n",
    "\"\"\"\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "def find_best_match(reference, candidates):\n",
    "    return max(candidates, key=lambda x: SequenceMatcher(None, reference, x).ratio())\n",
    "\n",
    "# Extract the answer between <answer> and </answer> tags\n",
    "import re\n",
    "\n",
    "pred_match = re.search(r'<answer>(.*?)</answer>', pred, re.DOTALL)\n",
    "if not pred_match:\n",
    "    pred_match = re.search(\n",
    "        r'\\{answer\\}\\s*([^\\n]+)',\n",
    "        r'\\{[A-Za-z_]+\\}\\s*(.+)',\n",
    "        pred,\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "if pred_match:\n",
    "    extracted_pred = pred_match.group(1).strip().lower()\n",
    "    print(extracted_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cartridges",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
